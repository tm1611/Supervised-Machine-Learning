{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification \n",
    "\n",
    "## 1. Introduction\n",
    "The following Notebook demonstrates a Naive Bayes Classifier to identify messages marked as \"spam\" or \"no spam\". Our data is downloaded from [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "Our outcome variable \"y\" indicates whether a message is considered to be \"spam\" or \"not\". Each observation in the dataset consists of  outcome variable y and is associated with one message. The objective here is to build a model that takes in a message and classifies this message as \"spam\" or \"no spam\" that can be applied to new messages with unknown outcome variable y. This is done by finding a model that maps each message to a probability being spam first, then deciding on a probability cutoff as of which a message is likely to be \"spam\".\n",
    "\n",
    "#### Multinomial Naive Bayes\n",
    "This algorithm is based on the theorem by Bayes:\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A|B) &= \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\end{align}\n",
    "$$\n",
    "and estimates the conditional probability of a particular word given a class as the relative frequence of this word in documents belonging to a specific class. Number of occurences are taken into account.\n",
    "\n",
    "The multinomail Naive Bayes classifier is well-suited to be used in situations of text classification and makes the assumption that features are independent. Even though this is hardly true, it generally performs good in this context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# import display function\n",
    "from IPython.display import display\n",
    "\n",
    "# Import data (seperator as tab, colnames\n",
    "df = pd.read_table(\"data/data_SMSSpam\", sep=\"\\t\", names=[\"label\", \"sms_message\"])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Data\n",
    "- Two columns. \n",
    " - Column [,1]: \"ham\" (no spam) or \"spam\". \n",
    " - Column [,2]: text of SMS message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Convert labels to binary variables: \n",
    " - ham := 0 for no spam and spam := 1.\n",
    " - Use map method to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define mapping\n",
    "di = {\"ham\": 0, \"spam\":1}\n",
    "\n",
    "# Apply mapping\n",
    "df[\"label\"] = df.label.map(di)\n",
    "\n",
    "# Show results\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text to numbers: Bag of Words in scikit-learn\n",
    "We have to convert the text messages to numbers (vectors of numbers) that can be used by our algorithms. A simple way to do this is to use the bag-of-words representation, yielding a vectorized dictionary consisting of the occurences of words. It is called \"bag\" because any structureal order of the relations of words to each other is dismissed. In sklearn, this model is denoted as `CountVectorizer()`.  \n",
    "\n",
    "- Objective: Convert set of text to a frequency distribution matrix (vectorization)\n",
    "- Use count vector: [count vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) \n",
    "\n",
    "In the following, we will first go through a simple example of how this is done and how it looks like before applying this method to our spam dataset.\n",
    "\n",
    "### Example I: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Import Count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Simple example data\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',]\n",
    "\n",
    "# Instantiate object of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit to our data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# extract feature names\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix shows that the word \"and\" is only present in the third observation once (row three, column one). \"Document\" occurs once in text 1 as well as text 4 and occurs twice in the second text. \n",
    "\n",
    "### Example II: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are', 'call', 'from', 'hello', 'home', 'how', 'me', 'money', 'now', 'tomorrow', 'win', 'you']\n",
      "[[1 0 0 1 0 1 0 0 0 0 0 1]\n",
      " [0 0 1 0 1 0 0 1 0 0 2 0]\n",
      " [0 1 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 1 0 2 0 0 0 0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>call</th>\n",
       "      <th>from</th>\n",
       "      <th>hello</th>\n",
       "      <th>home</th>\n",
       "      <th>how</th>\n",
       "      <th>me</th>\n",
       "      <th>money</th>\n",
       "      <th>now</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>win</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
       "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
       "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
       "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
       "3    0     1     0      2     0    0   0      0    0         1    0    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it first on the already known documents-list\n",
    "documents = ['Hello, how are you!',\n",
    "                'Win money, win from home.',\n",
    "                'Call me now.',\n",
    "                'Hello, Call hello you tomorrow?']\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# fit data and return matrix\n",
    "count_vector = count_vector.fit(documents)\n",
    "\n",
    "# get feature names\n",
    "names = count_vector.get_feature_names()\n",
    "count_vector = count_vector.transform(documents)\n",
    "\n",
    "# Convert to matrix \n",
    "doc_array = count_vector.toarray()\n",
    "\n",
    "print(names)\n",
    "print(doc_array)\n",
    "\n",
    "# Frequency matrix\n",
    "frequency_matrix = pd.DataFrame(columns=names, data=doc_array)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Spam Classification: \n",
    "Note that in the case of large datasets there will be certain fill words (e.g. \"is\", \"the\", and alike which should be dealt with by using \"stop_words\" or the [tfidf](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 5572\n",
      "Number of rows in the training set: 4179\n",
      "Number of rows in the test set: 1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TM\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1)\n",
    "\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modeling\n",
    "\n",
    "Applying Bag of Words processing to our dataset\n",
    " \n",
    "- i) fit our training data into CountVectorizer() \n",
    "- ii) Transform testing data to return the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem implementation\n",
    "- Use Bayes Algorithm to make predictions and classify a message as spam or not spam\n",
    "- Bayes Algorithm is composed of a prior (probabilities that we are aware of or that is given to us) and the posterior (probabilities we are looking to compute using the priors)\n",
    "- Algorithm considers features that it is using to make the predictions to be independent of each other, which may not always be the case. \n",
    "- More precisely, if we have more than one feature we will assume that this additional feature is independent of the first feature which may or may not be true\n",
    "\n",
    "In a next step we will extend Bayes to consider cases where we have more than one feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula for the Naive Bayes theorem:\n",
    "$$\n",
    "\\begin{equation}\n",
    "P(y| x_1, ..., x_n) = \\frac{P(y)P(x_1, ...,x_n|y)}{P(x_1,...,x_n)}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes implementation using scikit-learn\n",
    "- Use `naive_bayes` method from `sklearn` to make predictions\n",
    "- Use multinomial Naive Bayes implementation (suitable for classification with discrete features, word counts for text clasification). \n",
    "- Input: Integer of word counts\n",
    "- Alternatively: Gaussian Naive Bayes is better suited for continous data as it assumes that the input data has a Gaussian (normal) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit trainig data\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n",
    "# Initialize object\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Fit object to trining data\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = naive_bayes.predict(testing_data)\n",
    "print(predictions[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Model Evaluation: \n",
    "- **Accuracy** measures how often the classifier makes the correct prediction. It's the ratio of the number of correct predictions to the total number of predictions (number of test data points). \n",
    "- **Precision** is the proportion of messages we classified as spam and actually were spam. It is a ratio of: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{True \\; Positives}{True \\; Positives + False \\; Positives}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- **Sensitivity** tells us what proportion of messages that actually were spam were classified by us as spam. Ratio of true positives (words classified as spam, and which are actually spam) to all the words that were actually spams, hence: \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{True \\; Positives}{True \\; Positives + False \\; Negatives}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- In a skewed classification problem, accuracy by itself is not a very good metric (e.g. only 2 spam vs 98 non-spam).\n",
    "- For such cases, precision and recall come in handy. They can be combined to get the F1 score, which is the weighted average of the precision and recall scores. \n",
    "- F1 score can range from 0 to 1, with 1 being the best possible score.\n",
    "\n",
    "In the following we'll be calculating all 4 metrics whose values can range from 0 to 1, having a score as close to 1 as possible is a good indicator of how well our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9885\n",
      "Precision score:  0.9721\n",
      "Recall score:  0.9405\n",
      "F1 score:  0.956\n"
     ]
    }
   ],
   "source": [
    "# Import metrics from sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate Scores\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions).round(4)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions).round(4)))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions).round(4)))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions).round(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"End of Notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
