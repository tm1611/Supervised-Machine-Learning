{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook consists of a brief demonstration on how to implement linear and regularized regression models using sklearn. Focus lies on the developer's perspective, i.e. on implementing and fitting the model. For a more thorough theoretical description beyond my short explanations, see one of many awesome ressources on the topic, for example:\n",
    "- Joshua D. Angrist, JÃ¶rn-Steffen Pischke: Mostly Harmless Econometrics\n",
    "- Jeffrey M. Woolridge: Introductory Econometrics\n",
    "- William H. Greene: Econometric Analysis\n",
    "- Fahrmeir, Kneib, Lang and Marx: Regression\n",
    "\n",
    "Source code of the imported functions can be found here:\n",
    "- [LinearRegression](https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/base.py#L362).\n",
    "- [Lasso](https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/linear_model/coordinate_descent.py#L811)\n",
    "- [PolynomialFeatures](https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/preprocessing/data.py#L1331)\n",
    "\n",
    "## Regression Models\n",
    "The main objective of regression models is to model the effect of a given set of explanatory variables $x_i$ on a variable y, which is called the dependent or response variable. We have different ways to to do this, depending on the kind of response variable and type of covariates. A common characteristic is that the relationship between y and x can be seperated in a deterministic part which we'd like to model and a stochastic error part $\\epsilon$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y = E(y|x) + \\epsilon = f(x) + \\epsilon \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Our primary goal is to use the given data $y_i, x_{i1}, ..., x_{ik}$ to estimate the deterministic part and seperate it from the stochastic error component $\\epsilon$.\n",
    "\n",
    "Commonly used estimation techniques are the normal form equation for simple models, maximum likelihood estimation (MLE) and, in particular used in machine learning (ML), gradient descent (GD).\n",
    "\n",
    "- **Normal Form Equation:** Closed form solution (gives the result directly) that minimizes the squared error.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\beta} = (X'X)^{-1}X'y\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- **Maximum Likelihood Estimation:** Relies on the maximization of the likelihood function (joint density of $y_i$) and answering the question: \"What are the most likely parameters for this specification?\".\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\theta|y) = \\prod_{i=1}^N L_i (\\theta|y_i, x_i) = \\prod_{i=1}^N f(y_i|x_i; \\theta)  \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Usually, it is easier to use the natural logartitm, yielding the log-likelihood function. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\underset{\\theta}{max} \\: log \\: L(\\theta) = \\underset{\\theta}{max} \\sum_{i=1}^N log \\: L_i(\\theta) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The Maximum Likelihood-estimate is defined as the solution to $s(\\beta) = 0$, where $s(\\beta)$ denotes the score-function, which is the first order condition of the the log-likelihood function wrt $\\beta$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s(\\beta) = \\sum_{i=1}^n \\frac{\\partial \\, log \\, L_i(\\beta)}{\\partial \\beta}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The solution can be found by numerical optimization algorithms (e.g. [Fisher Scoring](https://en.wikipedia.org/wiki/Scoring_algorithm) as a form of [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method). A good ressource on this is Greene (2003). \n",
    "\n",
    "- **Gradient Descent:** Generic optimization algorithm with the idea to change parameters iteratively in order to minimize a specified cost function. It measures the local gradient of the error function wrt the parameters and takes a \"step\" towards the direction of descending gradient. After each step, the gradient is calculated again before taking another step. As the gradient is zero, a minimum is reached.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "from time import time\n",
    "start_notebook = time()\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression\n",
    "Linear regression is the most commonly used form of a regression model. The deterministic part is modeled as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(y|x) &= x'\\beta \\\\\n",
    "&= \\beta_0 + \\beta_1 x_1 + ... + \\beta_k x_k \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- y is the observed dependent variable \n",
    "- x denotes covariates or independent variables\n",
    "- $\\beta$ is a parameter vector, which can be interpreted as partial derivatives of the dependent variable wrt the independent variable. Another explanation which is probably more intuitive is to perceive them as weights of respective x vector.  \n",
    "\n",
    "Because we are modeling the relation between the conditional expectation and covariates the model yields the expected value of y (or arithmetic mean). There are other models which relate the covariates to the median (Median regression) or specific quantiles (Quantile regression, see below). Here, we observe x and want to model the relation to the mean of y.\n",
    "\n",
    "A linear, additive relationship between y and x is assumed. As aforementioned, this relationship will never be perfect and, therefore, will have a stochastic error part. Hence, the model can be expressed as: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= \\beta_0 + \\beta_1 x_{1} + ... + \\beta_k x_k + \\epsilon_i, \\\\\n",
    " &= x_i' \\beta + \\epsilon_i, \\hspace{7mm} \n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "Assumptions of the standard linear regression model are that the errors $\\epsilon$ are independent and identically distributed (i.i.d assumption) with\n",
    "$$E(\\epsilon_i) = 0 \\hspace{10mm} Var(\\epsilon_i) = \\sigma^2,$$\n",
    "\n",
    "This assertion includes various important assumptions about the error at once. In particular, this includes the assumption of \n",
    "- **Strict exogeneity**, meaning that the error is uncorrelated with the regressors x $E(x' \\epsilon) = 0 $),\n",
    "- Assumption of **Spherical errors**, where $Var(\\epsilon | X) = \\sigma^2 I_n$. Otherwise, inference is invalid and estimator not efficient. Note that this can further be subdivided into two parts of problems to the error\n",
    " - We assume **homoscedastic errors**: $E(\\epsilon_i^2 | X) = \\sigma^2$ for all observations\n",
    " - and **no autocorrelation:** $E[\\epsilon_i \\epsilon_j | X] = 0$, for $i \\neq j$.\n",
    "\n",
    "In addition, it is sometimes assumed that errors are normally distributed to establish certain finite-sample properties.\n",
    "\n",
    "$$ \\epsilon_i \\sim N(0,\\sigma^2)$$\n",
    "\n",
    "We will use the `LinearRegression()` fucntion of the `sklearn.linear_model` class. Documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Linear Regression Example I: Life Expectancy\n",
    "\n",
    "Predict life expectancy from BMI\n",
    "\n",
    "Steps:\n",
    "- Imports\n",
    "- Load data\n",
    "- Instantiate `LinearRegression()` class.\n",
    "- Fit data\n",
    "- Predict life expectancy using a theoretical BMI of 26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20.62058\n",
      "1    26.44657\n",
      "2    24.59620\n",
      "3    27.63048\n",
      "4    22.25083\n",
      "Name: BMI, dtype: float64\n",
      "0    52.8\n",
      "1    76.8\n",
      "2    75.5\n",
      "3    84.6\n",
      "4    56.7\n",
      "Name: Life expectancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Additional imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 1: Load the data using pandas\n",
    "data = pd.read_csv(\"data/data_bmi_and_life_expectancy.csv\")\n",
    "x = data[\"BMI\"]\n",
    "y = data[\"Life expectancy\"]\n",
    "\n",
    "print(x.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1379cbd1a20>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "colors = (0,0,0)\n",
    "area = np.pi*3\n",
    "\n",
    "plt.scatter(x, y, s = area, c = colors, alpha = 0.7)\n",
    "plt.title(\"Scatterplot of Life Expectancy and BMI \")\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Life Expectancy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Life Expectancy: 72.71\n",
      "Intercept:  7.2278\n",
      "Coefficient:  2.5185\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a linear regression model \n",
    "reg = LinearRegression()\n",
    "reg = reg.fit(data[[\"BMI\"]], data[[\"Life expectancy\"]]) \n",
    "\n",
    "# Step 3: Predict life expectancy of a BMI of 26 \n",
    "BMI = 26\n",
    "life_exp = reg.predict(BMI).round(2)[0][0]\n",
    "print(\"Predicted Life Expectancy:\", life_exp)\n",
    "\n",
    "# Coefficients\n",
    "bhat0 = round(reg.intercept_[0],4)\n",
    "bhat1 = round(reg.coef_[0][0],4)\n",
    "\n",
    "print(\"Intercept: \", bhat0)\n",
    "print(\"Coefficient: \", bhat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Linear Regression II: Boston data\n",
    "\n",
    "Use sklearn dataset API to load diabetes [data](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes). Note that a dictionary-like object is returned, consisting of:\n",
    "- target (y): Regression target for each sample, dependent variable\n",
    "- data (X): Data to learn, independent variables or feature matrix of variables.\n",
    "- other information on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "boston_data = datasets.load_boston()\n",
    "x = boston_data[\"data\"]\n",
    "y = boston_data[\"target\"]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sample house:  23.68\n",
      "b1:-0.1072\n",
      "b2:0.0464\n",
      "b3:0.0209\n",
      "b4:2.6886\n",
      "b5:-17.7958\n",
      "b6:3.8048\n",
      "b7:0.0008\n",
      "b8:-1.4758\n",
      "b9:0.3057\n",
      "b10:-0.0123\n",
      "b11:-0.9535\n",
      "b12:0.0094\n",
      "b13:-0.5255\n"
     ]
    }
   ],
   "source": [
    "# Linear regression for prediction\n",
    "reg = LinearRegression()\n",
    "reg.fit(x,y)\n",
    "\n",
    "# Prediction\n",
    "sample_house = [[2.29690000e-01, 0.00000000e+00, 1.05900000e+01, 0.00000000e+00, 4.89000000e-01,\n",
    "                6.32600000e+00, 5.25000000e+01, 4.35490000e+00, 4.00000000e+00, 2.77000000e+02,\n",
    "                1.86000000e+01, 3.94870000e+02, 1.09700000e+01]]\n",
    "\n",
    "prediction = reg.predict(sample_house).round(2)\n",
    "print(\"Prediction for sample house: \",prediction[0])\n",
    "\n",
    "for i in range(len(reg.coef_)):\n",
    "    print(\"b\"+str(i+1)+\":\"+str(reg.coef_[i].round(4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Linear Regression III: Diabetes\n",
    "The following code shows how to ... For illustration purposes only one feature is considered (x3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of full dataset: (442, 10)\n",
      "\n",
      " [[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
      "  -0.04340085 -0.00259226  0.01990842 -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 -0.02632783 -0.00844872 -0.01916334\n",
      "   0.07441156 -0.03949338 -0.06832974 -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 -0.00567061 -0.04559945 -0.03419447\n",
      "  -0.03235593 -0.00259226  0.00286377 -0.02593034]\n",
      " [-0.08906294 -0.04464164 -0.01159501 -0.03665645  0.01219057  0.02499059\n",
      "  -0.03603757  0.03430886  0.02269202 -0.00936191]\n",
      " [ 0.00538306 -0.04464164 -0.03638469  0.02187235  0.00393485  0.01559614\n",
      "   0.00814208 -0.00259226 -0.03199144 -0.04664087]]\n",
      "\n",
      "Shape of x3:  (442, 1)\n"
     ]
    }
   ],
   "source": [
    "# Additional imports\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Data exploration\n",
    "X_full = diabetes[\"data\"]\n",
    "print(\"Shape of full dataset:\", X_full.shape)\n",
    "print(\"\\n\",X_full[:5,])\n",
    "\n",
    "# Take out only third feature x3\n",
    "x3 = diabetes.data[:, np.newaxis, 2]\n",
    "print(\"\\nShape of x3: \", x3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  152.0 \n",
      "Coefficient:  998.58\n",
      "MSE:  4061.83\n",
      "R2:  0.23\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1379df16710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split data into training/testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x3, \n",
    "                                                    diabetes.target, \n",
    "                                                    test_size =0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Instantiate regression object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to object\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Intercept: \", reg.intercept_.round(2) ,\"\\nCoefficient: \", reg.coef_[0].round(2) )\n",
    "\n",
    "# Predictions\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "# MSE\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred).round(2))\n",
    "\n",
    "# R-squared\n",
    "print(\"R2: \", r2_score(y_test, y_pred).round(2))\n",
    "\n",
    "# Calculate vectorized form of t-values\n",
    "\n",
    "# Plots\n",
    "plt.scatter(x_test, y_test, color=\"black\")\n",
    "plt.plot(x_test, y_pred, color =\"blue\", linewidth=2)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Polynomial Regression\n",
    "We will now assume a nonlinear relationship between the conditional mean of y and x, for example\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "E(y|x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ... +  \\epsilon  \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore, we will add additional polynomials of x. This is called **polynomial regression**. Note that we can use this kind of regressions to fit nonlinear data with a linear model specification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [ 3.37563501 -6.28126025 -2.3787942   0.55307182  0.22699807]\n"
     ]
    }
   ],
   "source": [
    "# Import polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Data\n",
    "data = pd.read_csv(\"data/data_poly_reg.csv\")\n",
    "x = data[\"Var_X\"].values.reshape(-1,1)\n",
    "y = data[\"Var_Y\"].values\n",
    "\n",
    "# Instantiate polyomial object\n",
    "poly_feat = PolynomialFeatures(degree = 4)\n",
    "\n",
    "# Fit polynomial object to x\n",
    "x_poly = poly_feat.fit_transform(x)\n",
    "\n",
    "# Polynomial regression\n",
    "poly_reg = LinearRegression(fit_intercept = False)\n",
    "poly_reg.fit(x_poly, y)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Coefficients: \", poly_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do** \n",
    "- Show that unconstrained polynomial regression tends to overfit and therefore often suffers from poor generalizability. \n",
    "- Show and explain the bias-variance tradeoff\n",
    " - Compare and contrast linear regression and polynomial regression as two complete opposites.\n",
    "- Add another polynomial regression using more complex data and add plots\n",
    "- Regularized regression as a middle ground to balance bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Regularized Regression\n",
    "We have seen two \"extreme\" cases of regression models. Whereas, linear regression fits a simple straight line to the data, polynomial regression can fit curves pretty well at the cost of generalizability.  \n",
    "\n",
    "In general, these are two extreme forms of overfitting and underfitting. See also general considerations, which are usually discussed as [Bias-variance tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff).\n",
    "\n",
    "There are two main problems with these methods:\n",
    "- Underfitting: Fitting a simple curve to the data is often not flexible enough and misses some relations. \n",
    " - Example: Linear regression\n",
    " - High bias, low variance\n",
    "- Overfitting: Very flexible methods are sensitive to fitting the noise in the data, hereby diluting the underlying signal that we are interested in.\n",
    " - Example: Polynomial regression\n",
    " - Low bias, high variance\n",
    " \n",
    "A good way to reduce overfitting is to regularize the model, i.e. penalize complexity. This can be implemented by considering a penalized least squares (PLS) objective function \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\beta_{PLS} = arg \\, \\underset{\\beta}{min} \\,[(y-X \\beta)'(y-X \\beta) + \\lambda \\cdot pen(\\beta)]\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "In **Ridge Regression**, the resulting penalty is simply given by the sum of the squared coefficients: \n",
    "\n",
    "$$pen(\\beta) = \\sum_{j=0}^k \\beta_j^2 = \\beta' \\beta$$\n",
    "\n",
    "**Least absolute Shrinkage and Selection Operator (LASSO)** replaces the penalty of squared regression coefficients with absolute values\n",
    "\n",
    "$$pen(\\beta) = \\sum_{j=0}^k |\\beta_j| $$\n",
    "\n",
    "leading to \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{LASSO} = arg \\, \\underset{\\beta}{min} \\,(y-X \\beta)'(y-X \\beta) + \\lambda \\cdot \\sum_{j=1}^k |\\beta_k|\n",
    "\\end{align}\n",
    "$$ \n",
    "\n",
    "Both models can be used to balance between fit to the data and regularized solutions by modifying the smoothing parameter $\\lambda$. Ridge regression adds a quadratic penalty with large impact on big coefficients and small penalty for small coefficient values. LASSO penalties increase at a slower rate for large coefficient values, leading to the behavior that small coefficients will be more strongly drawn towards zero, while larger coefficients will be less affected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.      2.3579  2.0044 -0.0551 -3.9281  0.    ]\n"
     ]
    }
   ],
   "source": [
    "# Regularization\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "# Assign the data to predictor and outcome variables\n",
    "train_data = pd.read_csv(\"data/data_regularization.csv\", header= None)\n",
    "X = train_data.iloc[:, :6]\n",
    "y = train_data.iloc[:, 6]\n",
    "\n",
    "# Lasso Reg\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X,y)\n",
    "\n",
    "reg_coef = lasso_reg.coef_\n",
    "print(\"Coefficients:\",reg_coef.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0        1         2        3        4        5\n",
      "0  1.25664  2.04978  -6.23640  4.71926 -4.26931  0.20590\n",
      "1 -3.89012 -0.37511   6.14979  4.94585 -3.57844  0.00640\n",
      "2  5.09784  0.98120  -0.29939  5.85805  0.28297 -0.20626\n",
      "3  0.39034 -3.06861  -5.63488  6.43941  0.39256 -0.07084\n",
      "4  5.84727 -0.15922  11.41246  7.52165  1.69886  0.29022\n",
      "\n",
      " 0    12.31798\n",
      "1    23.67628\n",
      "2    -1.53459\n",
      "3   -24.68670\n",
      "4    17.54122\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "Coefficients: [  0.       3.9075   9.0258  -0.     -11.783    0.4534]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assign the data to predictor and outcome variables\n",
    "train_data = pd.read_csv(\"data/data_regularization.csv\", header= None)\n",
    "\n",
    "X = train_data.iloc[:,0:-1]\n",
    "y = train_data.iloc[:,-1]\n",
    "\n",
    "# show data\n",
    "print(X.head())\n",
    "print(\"\\n\", y.head())\n",
    "\n",
    "# Standardize \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Lasso Reg\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_scaled,y )\n",
    "\n",
    "reg_coef = lasso_reg.coef_\n",
    "print(\"\\nCoefficients:\",reg_coef.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -0.0297   5.0902   9.7168  -0.6581 -12.411    1.6931]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"data/data_regularization.csv\", header= None)\n",
    "\n",
    "X = train_data.iloc[:,0:-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "# Standardize \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Lasso Reg\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X_scaled,y )\n",
    "\n",
    "reg_coef = ridge_reg.coef_\n",
    "print(\"Coefficients:\", reg_coef.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to do**\n",
    "- Add visualizations, a more complex dataset and compare to linear model. Compare different values of $\\lambda$.\n",
    "- Add Inference\n",
    "- [Lasso and Elastic Net](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py)\n",
    "- [Lasso model selection: Cross-validation / AIC / BIC](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html#sphx-glr-auto-examples-linear-model-plot-lasso-model-selection-py)\n",
    "- [Lasso path using LARS](https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_lars.html#sphx-glr-auto-examples-linear-model-plot-lasso-lars-py)\n",
    "- [Cross-Validation](https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Quantile Regression \n",
    "Quantile regression (QR) has become a widely used statistical method to analyse the relationship between dependent and independent variables. Whereas ordinary least squares (OLS) relates covariates to the conditional expectation function, QR links to the conditional quantile function:\n",
    "$$\n",
    "\\begin{align}\n",
    "Q_{\\tau} (y|x) = x' \\beta_{\\tau}\n",
    "\\end{align}\n",
    "$$\n",
    "meaning that given x, what is the respective $\\tau$-quantile of y, giving additional insights about the distribution of y. It is often used to examine the effect of x on the tails of the distribution of y. For example, to answer questions like \"What is the effect of x on low income earners in the first decile?\" (e.g. the first of ten quantiles seperating the observations in ten parts). \n",
    "\n",
    "For more information and applications in R, see my repository on [Quantile Regression](https://github.com/tm1611/Quantile-Regression-Project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time of the script: 2.81\n"
     ]
    }
   ],
   "source": [
    "end_notebook = time()\n",
    "time_notebook = end_notebook - start_notebook\n",
    "print(\"Total running time of the script:\", round(time_notebook,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
